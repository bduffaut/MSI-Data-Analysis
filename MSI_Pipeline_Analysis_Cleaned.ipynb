{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "924ddc16",
   "metadata": {},
   "source": [
    "# Microsatellite Instability (MSI) Analysis Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22791b1",
   "metadata": {},
   "source": [
    "This Jupyter notebook demonstrates a simplified and fully anonymized version of an MSI analysis pipeline used in a research lab setting. The pipeline detects microsatellite instability in cancer samples using a set of genomic loci. **All data shown is simulated or anonymized.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252e880e",
   "metadata": {},
   "source": [
    "## Overview of the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c2cb46",
   "metadata": {},
   "source": [
    "- Load sample output files from MSI sensor or similar tools\n",
    "- Count the number of unstable loci per sample\n",
    "- Classify samples into `MSI-High`, `MSI-Low`, or `MSI-Stable`\n",
    "- Summarize results for downstream reporting or research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7bc3ff",
   "metadata": {},
   "source": [
    "## ðŸ› Code Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909f66e1",
   "metadata": {},
   "source": [
    "Below is the Python code used to implement the analysis pipeline. It includes directory scanning, parsing results, and classifying MSI status per sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0678e2f2",
   "metadata": {},
   "source": [
    "## Output Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a16cd1f",
   "metadata": {},
   "source": [
    "After processing, the notebook prints a summary table of MSI classifications and optionally generates histograms or plots for visual analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5320d56c",
   "metadata": {},
   "source": [
    "## **Disclaimer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beddabe",
   "metadata": {},
   "source": [
    "This notebook is a **sanitized** and **anonymized** demo. It does not contain any protected health information (PHI) or real patient data. Shared for educational and portfolio purposes only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b203c11-8a37-413d-a1b7-a68e581ee21a",
   "metadata": {},
   "source": [
    "### MSI Pipeline Analysis\n",
    "#### Gathers data from MSI pipeline runs and outputs tables/histograms/scatter plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e52b27-4b74-41f3-89fb-59c96f9ee6d9",
   "metadata": {},
   "source": [
    "#### imports all necessary libraries and initiates loci_data for use in for-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33955d3-fa5a-452a-98df-4bd2265915e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "folders = os.listdir('project/MSI_Analyses')\n",
    "\n",
    "#enter loci data and make loci_df\n",
    "loci_data = {\n",
    "    \"Chromosome\": [\n",
    "        \"chr4\", \"chr2\", \"chr14\", \"chr2\", \"chr11\", \"chr11\", \"chr11\", \n",
    "        \"chr11\", \"chr7\", \"chr17\", \"chr13\", \"chr4\", \"chr6\", \"chr9\"\n",
    "    ],\n",
    "    \"Start\": [\n",
    "        55598211, 47641559, 23652346, 95849361, 102193508, 108188266, \n",
    "        108114661, 108141955, 116409675, 29508819, 31722620, 153268227, \n",
    "        117725383, 135773000\n",
    "    ],\n",
    "    \"Target_Loci\": [\n",
    "        \"BAT25\", \"BAT26\", \"NR-21\", \"NR-24\", \"NR-27\", \"T13\", \"T15-1\", \n",
    "        \"T15-2\", \"T15-3\", \"T16\", \"HSPH1-T17\", \"A14\", \"A15\", \"A18\"\n",
    "    ]\n",
    "}\n",
    "# New data\n",
    "new_loci = { \"Chromosome\": [\"chr1\", \"chr2\", \"chr7\", \"chr11\", \"chr13\", \"chr17\", \"chr1\", \"chr3\", \"chr3\", \"chr6\", \"chr8\", \"chr10\", \"chr11\", \"chr12\", \"chr18\"], \"Start\": [120053340, 225422600, 116409675, 108114661, 48954159, 29559061, 162736821, 10076008, 69988437, 51503597, 141754888, 43595836, 119144791, 112893675, 45395845],\"Target_Loci\": [\"BAT-40\", \"CUL-22\", \"MET-15\", \"ATM-15\", \"RB1-13\", \"NF1-26\", \"DDR-11\", \"FANC-21\", \"MITF-14\", \"PKHD-18\", \"PTK-16\", \"RET-14\", \"CBL-17\", \"PTPN-17\", \"SMAD-18\"] }\n",
    "# Combine existing and new\n",
    "loci_data[\"Chromosome\"].extend(new_loci[\"Chromosome\"])\n",
    "loci_data[\"Start\"].extend(new_loci[\"Start\"])\n",
    "loci_data[\"Target_Loci\"].extend(new_loci[\"Target_Loci\"])\n",
    "loci_df = pd.DataFrame(loci_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93522cbd-09ee-4a27-946b-68b5521388c7",
   "metadata": {},
   "source": [
    "#### Runs a loop for each of the 10 samples in the directory folder. \n",
    "#### Loads the data into dataFrames then produces filtered_df,result_df, scatter plot, and histograms for each loci. \n",
    "#### If part of the positive group of samples it will add to combined_df for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0155e05a-e6d3-4a51-b8e0-a2f7823e591f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#runs for each file\n",
    "combined_df = pd.DataFrame()\n",
    "end_codes = {'730','281','460','174','486','684','090'}\n",
    "\n",
    "\n",
    "for folder_name in folders:\n",
    "    \n",
    "    #gather the directory and file id\n",
    "    if \"DRAGEN Analysis\" in folder_name:\n",
    "        file_id = folder_name.split()[0]\n",
    "        dir = f\"project/MSI_Analyses/{folder_name}/{file_id}\"\n",
    "        # \n",
    "    else:\n",
    "        continue\n",
    "    print(file_id)\n",
    "\n",
    "    #load in data to dataFrames\n",
    "    microsat_diff_df = pd.read_csv(f\"{dir}/{file_id}.microsat_diffs.txt\",delimiter='\\t')\n",
    "    microsat_tumor_df = pd.read_csv(f\"{dir}/{file_id}.microsat_tumor.dist\",delimiter='\\t')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Rename columns\n",
    "    microsat_diff_df.rename(columns={'#Chromosome':'Chromosome'},inplace=True)\n",
    "    microsat_tumor_df.rename(columns={'#chromosome':'Chromosome', 'location':'Start','repeat_unit_bases':'RepeatUnit'},inplace=True)\n",
    "    \n",
    "   \n",
    "    # merge data on chromosome, start,repeatUnit\n",
    "    merged_df = pd.merge(microsat_diff_df, microsat_tumor_df, on=['Chromosome', 'Start', 'RepeatUnit'])\n",
    "    # drop unnecessary columns\n",
    "    merged_df.drop(['PassFilter', 'covered'], axis=1,inplace = True)\n",
    "\n",
    "\n",
    "    # Filter values and sort in ascending order by PValue\n",
    "    filtered_df = merged_df[(merged_df.Assessed == True) & (merged_df.Distance >= 0.15) & (merged_df.PValue <= 0.015)]\n",
    "    filtered_df = filtered_df.sort_values(by='PValue', ascending=True)\n",
    "    \n",
    "    filtered_df.to_csv(f'{dir}/{file_id}_outputs/{file_id}_filtered.csv',index=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Export scatter plots of merged_df\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(filtered_df['Distance'], filtered_df['PValue'])\n",
    "    plt.title('Scatter plot of Distance vs PValue')\n",
    "    plt.xlabel('Distance')\n",
    "    plt.ylabel('PValue')\n",
    "    plt.savefig(f'{dir}/{file_id}_outputs/{file_id}_filtered_scatter.png')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # merge with loci_df\n",
    "    result_df = merged_df.merge(loci_df, on=['Chromosome', 'Start'], how='inner')\n",
    "    \n",
    "    \n",
    "    # re-order result to match the loci_df\n",
    "    result_df.set_index(\"Target_Loci\",inplace=True)\n",
    "    loci_ordered = loci_df[\"Target_Loci\"]\n",
    "    result_df = result_df.loc[loci_ordered,:]\n",
    "    result_df = result_df[(result_df.Assessed == True)]\n",
    "    \n",
    "    \n",
    "    # Reset the index to convert the index column to a normal column\n",
    "    result_df = result_df.reset_index()\n",
    "    result_df.to_csv(f'{dir}/{file_id}_outputs/{file_id}_final.csv',index=False)\n",
    "    code = file_id.split('_')[-1][-3:]\n",
    "    \n",
    "    #End codes contains the positive sample codes\n",
    "    if code in end_codes:\n",
    "        combined_df = pd.concat([combined_df,filtered_df],ignore_index=True)\n",
    "             \n",
    "    # Export Histograms for each loci\n",
    "    msi_loci = [\"BAT25\", \"BAT26\", \"NR-21\", \"NR-24\", \"NR-27\"]\n",
    "\n",
    "    # Load combined_df for normals distribution\n",
    "    combined_df = pd.read_csv('/data/project/MSI_Normals_Panel/analysis_files/normals_dist_sum.csv')\n",
    "    num_samples = len(os.listdir(dir))\n",
    "\n",
    "    num_loci = len(msi_loci)\n",
    "    col = 2\n",
    "    row = math.ceil(num_loci / col)\n",
    "    fig, axes = plt.subplots(row, col, figsize=(10 * col, 6 * row))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Overlayed histogram outputs\n",
    "    for i, marker in enumerate(msi_loci):\n",
    "        # Filter the DataFrame for the current marker\n",
    "        dist_string = result_df[result_df['Target_Loci'] == marker]['length_distribution'].values[0]\n",
    "        dist_list = list(map(int, dist_string.split(',')))\n",
    "\n",
    "        normals_dist_string = combined_df[combined_df.Target_Loci == marker]['length_distribution'].values[0]\n",
    "        normals_dist_list = np.array(list(map(int, normals_dist_string.split(',')))) / num_samples\n",
    "\n",
    "        # Set the positions for Tumor and Normal bars\n",
    "        bar_width = 0.4\n",
    "        x_positions = np.arange(len(dist_list))\n",
    "\n",
    "        # Plot Tumor distribution\n",
    "        axes[i].bar(x_positions - bar_width / 2, dist_list, width=bar_width, alpha=0.5, label='Tumor', color='red')\n",
    "\n",
    "        # Plot Normal distribution\n",
    "        axes[i].bar(x_positions + bar_width / 2, normals_dist_list, width=bar_width, alpha=0.5, label='Normal', color='blue')\n",
    "        axes[i].set_xlabel(\"Additional Base Pairs (bp)\")\n",
    "        axes[i].set_ylabel(\"Read Counts\")\n",
    "        axes[i].set_title(f'MSI Distribution at {marker} Locus')\n",
    "        axes[i].grid(True)\n",
    "        axes[i].legend()\n",
    "\n",
    "    # Format and save output\n",
    "    plt.tight_layout()\n",
    "    output_filename = f'{dir}/{file_id}_outputs/loci_histograms.png'\n",
    "    plt.savefig(output_filename)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    \n",
    "    \n",
    "print('----------DONE-----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999f4a87-8a85-4ff4-b466-122dedb3c658",
   "metadata": {},
   "source": [
    "#### Uses combined_df to generate a table of the common loci and their distance, repeatUnit,Start location, Chromosome, and reference_allele for each. Threshold of 6 or 7 can be changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bacf09-83f0-471f-b06e-9f0c78ea66a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_columns = ['Chromosome', 'Start', 'RepeatUnit']\n",
    "grouped = combined_df.groupby(key_columns).size().reset_index(name='counts')\n",
    "threshold = 7\n",
    "common_groups = grouped[grouped['counts'] >= threshold]\n",
    "result_df = pd.merge(combined_df, common_groups[key_columns], on=key_columns, how='inner')\n",
    "result_df = result_df.drop_duplicates()\n",
    "result_df.sort_values('PValue', ascending = True, inplace = True)\n",
    "result_df.drop(['Distance','PValue','length_distribution'],inplace=True,axis=1)\n",
    "result_df.drop_duplicates(inplace=True) \n",
    "result_df.to_csv('common_positive_loci_7.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3255fc7c-aaf9-4018-bbae-651389decf37",
   "metadata": {},
   "source": [
    "#### For use of clearing all the output folders so you can rerun without errors and replace all the existing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f904ce7e-df4a-4e46-8a8b-b3c40d59aec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "def clear_folder(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.remove(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "\n",
    "\n",
    "for folder_name in folders:\n",
    "    #gather the directory and file id\n",
    "    if \"DRAGEN Analysis\" in folder_name:\n",
    "        file_id = folder_name.split()[0]\n",
    "        dir = f\"project/MSI_Analyses/{folder_name}/{file_id}\"\n",
    "    else:\n",
    "        continue\n",
    "    clear_folder(f'{dir}/{file_id}_outputs')\n",
    "    \n",
    "    print(f'done clearing {file_id}')\n",
    "    \n",
    "    \n",
    "    \n",
    "print('------------DONE---------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79274941-913a-44f2-9bf1-f89c451bc291",
   "metadata": {},
   "source": [
    "#### Creates the final table output containing comparison of protein mutation with distance/positivity of common loci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c23d853-d0e3-4389-ad07-7ebfa8f963c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "caseList_df = pd.read_csv('CaseList+Dir.csv')\n",
    "MMR_df = pd.read_csv('Cases_with_MMR_CSV - Cases_with_MMR_CSV.csv')\n",
    "caseList_df.rename(columns={'Case #':'Case'}, inplace=True)\n",
    "combined_df = pd.merge(MMR_df, caseList_df, on='Case')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "combined_df.drop(['Date Created', 'Laboratory', 'Req Patient/Source Name', 'Authorizing Provider', 'Case Status', 'Tasks', 'Case Type'], axis=1, inplace=True)\n",
    "\n",
    "# Initialize loci columns with None\n",
    "loci_list = ['BAT25', 'BAT26', 'NR-21', 'NR-24', 'NR-27']\n",
    "for loci in loci_list:\n",
    "    combined_df[loci] = None\n",
    "\n",
    "# Remove front portion and rename\n",
    "combined_df['SAMPLE_DIR_PATH'] = combined_df['SAMPLE_DIR_PATH'].apply(lambda x: x.split('/')[-1])\n",
    "combined_df.rename(columns={'SAMPLE_DIR_PATH': 'file_id'}, inplace=True)\n",
    "\n",
    "# Manually entered MMRIHC column\n",
    "combined_df['MLH1'] = ['+','-','+','+','-','+','+','+','-','-']\n",
    "combined_df['MSH2'] = ['-','-','-','-','-','-','-','-','-','-']\n",
    "combined_df['MSH6'] = ['-','-','-','-','-','-','-','-','+','-']\n",
    "combined_df['PMS2'] = ['+','-','+/-','+/-','-','+','+/-','+/-','-','-']\n",
    "\n",
    "# Remove MMRIHC Column\n",
    "combined_df.drop(['MMRIHC'], axis=1, inplace=True)\n",
    "\n",
    "folders = os.listdir('project/MSI_Analyses')\n",
    "\n",
    "def evaluate_loci(row):\n",
    "    return row['Distance']\n",
    "\n",
    "def get_data(row):\n",
    "    original_file_id = row['file_id']\n",
    "    modified_file_id = original_file_id.replace('_', '-')\n",
    "    complete_path = None\n",
    "    \n",
    "    # find *_final.csv\n",
    "    for folder_name in folders:\n",
    "        if modified_file_id in folder_name:\n",
    "            complete_path = f'project/MSI_Analyses/{folder_name}/{modified_file_id}/{modified_file_id}_outputs/{modified_file_id}_final.csv'\n",
    "            break\n",
    "\n",
    "    if complete_path and os.path.exists(complete_path):\n",
    "        temp_final_df = pd.read_csv(complete_path)\n",
    "        \n",
    "        # Update each locus column for this specific file_id\n",
    "        for loci in loci_list:\n",
    "            matching_row = temp_final_df[temp_final_df['Target_Loci'] == loci]\n",
    "            if not matching_row.empty:\n",
    "                row[loci] = evaluate_loci(matching_row.iloc[0])\n",
    "    \n",
    "    return row\n",
    "\n",
    "# Apply function\n",
    "combined_df = combined_df.apply(get_data, axis=1)\n",
    "\n",
    "# MSI status column \n",
    "def determine_msi_status(row):\n",
    "    positive_count = sum(row[loci] is not None and row[loci] >= 0.1 for loci in loci_list)\n",
    "    if positive_count >= 2:\n",
    "        return 'MSI High'\n",
    "    elif positive_count == 1:\n",
    "        return 'MSI Low'\n",
    "    else:\n",
    "        return 'MSI Stable'\n",
    "\n",
    "combined_df['MSI Status'] = combined_df.apply(determine_msi_status, axis=1)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "combined_df.drop(['Code', 'Case', 'POSITIVE'], axis=1, inplace=True)\n",
    "# print(combined_df.columns.tolist())\n",
    "combined_df.rename(columns={'file_id':'SAMPLE_DIR_PATH'},inplace=True)\n",
    "# Reorder columns\n",
    "final_column_order = ['SAMPLE_DIR_PATH', 'MLH1', 'MSH2', 'MSH6', 'PMS2'] + loci_list + ['MSI Status']\n",
    "combined_df = combined_df[final_column_order]\n",
    "\n",
    "print(combined_df)\n",
    "combined_df.to_csv('final_table.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099f4b1f-6225-4886-b152-9cadca206d1a",
   "metadata": {},
   "source": [
    "#### Creates a table which contains the total distances of all loci combined to achieve an \"MSI Score\" which is a total instability measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3003330-29d6-4730-a14e-dc95f9a25be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "caseList_df = pd.read_csv('CaseList+Dir.csv')\n",
    "caseList_df.drop(['Code','Case #','POSITIVE'],axis=1,inplace=True)\n",
    "caseList_df['SAMPLE_DIR_PATH'] = caseList_df['SAMPLE_DIR_PATH'].apply(lambda x: x.split('/')[-1])\n",
    "msi_score_df = pd.DataFrame()\n",
    "msi_score_df['SAMPLE'] = caseList_df['SAMPLE_DIR_PATH']\n",
    "\n",
    "def get_msi_score(row):\n",
    "    original_file_id = row['SAMPLE']\n",
    "    modified_file_id = original_file_id.replace('_', '-')\n",
    "    complete_path = None\n",
    "    \n",
    "    #find *final.csv\n",
    "    for folder_name in folders:\n",
    "        if modified_file_id in folder_name:\n",
    "            complete_path = f'project/MSI_Analyses/{folder_name}/{modified_file_id}/{modified_file_id}_outputs/{modified_file_id}_final.csv'\n",
    "            break\n",
    "\n",
    "    if complete_path and os.path.exists(complete_path):\n",
    "        temp_final_df = pd.read_csv(complete_path)\n",
    "        \n",
    "        # Sum all values\n",
    "        total_distance = temp_final_df['Distance'].sum()\n",
    "        row['MSI Score'] = total_distance\n",
    "    \n",
    "    return row\n",
    "\n",
    "\n",
    "msi_score_df = msi_score_df.apply(get_msi_score,axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(msi_score_df)\n",
    "msi_score_df.to_csv('MSI_Score_Table.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
